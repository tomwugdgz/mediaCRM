#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å¯¼å…¥å¯¼å‡ºå·¥å…·
æ”¯æŒExcelã€CSVç­‰æ ¼å¼çš„æ•°æ®å¯¼å…¥å¯¼å‡ºï¼Œä»¥åŠæ•°æ®æ¨¡æ¿ç”Ÿæˆ
"""

import pandas as pd
import sqlite3
from datetime import datetime
import os
import json
from typing import Dict, List, Optional, Any
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataImporter:
    """æ•°æ®å¯¼å…¥å¯¼å‡ºå·¥å…·ç±»"""
    
    def __init__(self, db_path: str = "inventory.db"):
        """
        åˆå§‹åŒ–æ•°æ®å¯¼å…¥å¯¼å‡ºå·¥å…·
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = db_path
        
        # å®šä¹‰æ ‡å‡†çš„æ•°æ®æ¨¡æ¿ç»“æ„
        self.templates = {
            'brands': {
                'columns': ['brand_name', 'contact_person', 'contact_phone', 'contact_email', 'brand_type', 'reputation_score'],
                'required': ['brand_name'],
                'defaults': {
                    'reputation_score': 5
                }
            },
            'inventory': {
                'columns': ['brand_name', 'product_name', 'category', 'quantity', 'original_value', 'market_value', 'expiry_date', 'storage_location'],
                'required': ['brand_name', 'product_name', 'category', 'quantity', 'original_value'],
                'defaults': {}
            },
            'media_resources': {
                'columns': ['media_name', 'media_type', 'location', 'market_price', 'actual_cost'],
                'required': ['media_name', 'media_type', 'location', 'market_price', 'actual_cost'],
                'defaults': {}
            },
            'sales_channels': {
                'columns': ['channel_name', 'channel_type', 'contact_person', 'contact_phone', 'commission_rate', 'payment_terms'],
                'required': ['channel_name', 'channel_type'],
                'defaults': {
                    'commission_rate': 0
                }
            }
        }
    
    def generate_template(self, template_type: str, filename: str = None) -> str:
        """
        ç”Ÿæˆæ•°æ®å¯¼å…¥æ¨¡æ¿
        
        Args:
            template_type: æ¨¡æ¿ç±»å‹ ('brands', 'inventory', 'media_resources', 'sales_channels')
            filename: è¾“å‡ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶å
        """
        if template_type not in self.templates:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡æ¿ç±»å‹: {template_type}")
        
        if not filename:
            filename = f"{template_type}_template_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        template_info = self.templates[template_type]
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        sample_data = self._generate_sample_data(template_type)
        df = pd.DataFrame(sample_data)
        
        # åˆ›å»ºExcelæ–‡ä»¶ï¼ŒåŒ…å«è¯´æ˜å’Œæ¨¡æ¿ä¸¤ä¸ªå·¥ä½œè¡¨
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # ä¸»æ¨¡æ¿å·¥ä½œè¡¨
            df.to_excel(writer, sheet_name='æ¨¡æ¿æ•°æ®', index=False)
            
            # è¯´æ˜æ–‡æ¡£å·¥ä½œè¡¨
            instructions = self._generate_instructions(template_type)
            instructions_df = pd.DataFrame(instructions)
            instructions_df.to_excel(writer, sheet_name='ä½¿ç”¨è¯´æ˜', index=False)
            
            # åˆ—è¯´æ˜å·¥ä½œè¡¨
            column_descriptions = self._generate_column_descriptions(template_type)
            desc_df = pd.DataFrame(column_descriptions)
            desc_df.to_excel(writer, sheet_name='åˆ—è¯´æ˜', index=False)
        
        logger.info(f"æ¨¡æ¿æ–‡ä»¶å·²ç”Ÿæˆ: {filename}")
        return filename
    
    def _generate_sample_data(self, template_type: str) -> List[Dict]:
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
        sample_data_map = {
            'brands': [
                {
                    'brand_name': 'å¯å£å¯ä¹',
                    'contact_person': 'å¼ ç»ç†',
                    'contact_phone': '13800138000',
                    'contact_email': 'zhang@coke.com',
                    'brand_type': 'é¥®æ–™',
                    'reputation_score': 9
                },
                {
                    'brand_name': 'è“æœˆäº®',
                    'contact_person': 'ææ€»ç›‘',
                    'contact_phone': '13900139000',
                    'contact_email': 'li@bluemoon.com',
                    'brand_type': 'æ—¥åŒ–',
                    'reputation_score': 8
                }
            ],
            'inventory': [
                {
                    'brand_name': 'å¯å£å¯ä¹',
                    'product_name': 'å¯å£å¯ä¹ç»å…¸è£…',
                    'category': 'é¥®æ–™',
                    'quantity': 1000,
                    'original_value': 45000.0,
                    'market_value': 30000.0,
                    'expiry_date': '2025-06-30',
                    'storage_location': 'ä»“åº“A'
                },
                {
                    'brand_name': 'è“æœˆäº®',
                    'product_name': 'è“æœˆäº®æ´—è¡£æ¶²',
                    'category': 'æ—¥åŒ–',
                    'quantity': 500,
                    'original_value': 25000.0,
                    'market_value': 20000.0,
                    'expiry_date': '2025-12-31',
                    'storage_location': 'ä»“åº“B'
                }
            ],
            'media_resources': [
                {
                    'media_name': 'ç¤¾åŒºé—¨ç¦å¹¿å‘Šä½A',
                    'media_type': 'ç¤¾åŒºé—¨ç¦',
                    'location': 'æœé˜³åŒºæŸå°åŒº',
                    'market_price': 5000.0,
                    'actual_cost': 200.0
                },
                {
                    'media_name': 'å†™å­—æ¥¼ç”µæ¢¯å¹¿å‘Šä½B',
                    'media_type': 'å†™å­—æ¥¼ç”µæ¢¯',
                    'location': 'CBDæŸå¤§å¦',
                    'market_price': 8000.0,
                    'actual_cost': 300.0
                }
            ],
            'sales_channels': [
                {
                    'channel_name': 'ç‹å›¢é•¿å›¢è´­',
                    'channel_type': 'Sçº§',
                    'contact_person': 'ç‹å›¢é•¿',
                    'contact_phone': '13700137000',
                    'commission_rate': 5.0,
                    'payment_terms': 'ç°ç»“'
                },
                {
                    'channel_name': 'ä¸´æœŸå¸‚åœºæ¡£å£A',
                    'channel_type': 'Açº§',
                    'contact_person': 'èµµè€æ¿',
                    'contact_phone': '13600136000',
                    'commission_rate': 0.0,
                    'payment_terms': 'æ‰¹é‡ç»“ç®—'
                }
            ]
        }
        
        return sample_data_map.get(template_type, [])
    
    def _generate_instructions(self, template_type: str) -> List[Dict]:
        """ç”Ÿæˆä½¿ç”¨è¯´æ˜"""
        instructions_map = {
            'brands': [
                {'æ­¥éª¤': '1', 'è¯´æ˜': 'åœ¨"æ¨¡æ¿æ•°æ®"å·¥ä½œè¡¨ä¸­å¡«å†™å“ç‰Œä¿¡æ¯'},
                {'æ­¥éª¤': '2', 'è¯´æ˜': 'å“ç‰Œåç§°ä¸èƒ½ä¸ºç©ºï¼Œå¿…é¡»å”¯ä¸€'},
                {'æ­¥éª¤': '3', 'è¯´æ˜': 'å“ç‰Œå£°èª‰è¯„åˆ†èŒƒå›´ä¸º1-10ï¼Œ10ä¸ºæœ€é«˜'},
                {'æ­¥éª¤': '4', 'è¯´æ˜': 'è”ç³»ä¿¡æ¯å¯é€‰ï¼Œä½†å»ºè®®å¡«å†™å®Œæ•´'},
                {'æ­¥éª¤': '5', 'è¯´æ˜': 'ä¿å­˜æ–‡ä»¶åä½¿ç”¨å¯¼å…¥åŠŸèƒ½å¯¼å…¥æ•°æ®'}
            ],
            'inventory': [
                {'æ­¥éª¤': '1', 'è¯´æ˜': 'åœ¨"æ¨¡æ¿æ•°æ®"å·¥ä½œè¡¨ä¸­å¡«å†™åº“å­˜ä¿¡æ¯'},
                {'æ­¥éª¤': '2', 'è¯´æ˜': 'å“ç‰Œåç§°å¿…é¡»å·²åœ¨ç³»ç»Ÿä¸­å­˜åœ¨'},
                {'æ­¥éª¤': '3', 'è¯´æ˜': 'å•†å“åç§°ã€å“ç±»ã€æ•°é‡ã€åŸå§‹ä»·å€¼ä¸ºå¿…å¡«é¡¹'},
                {'æ­¥éª¤': '4', 'è¯´æ˜': 'ä¿è´¨æœŸæ ¼å¼ä¸ºYYYY-MM-DDï¼Œå¯é€‰'},
                {'æ­¥éª¤': '5', 'è¯´æ˜': 'ä¿å­˜æ–‡ä»¶åä½¿ç”¨å¯¼å…¥åŠŸèƒ½å¯¼å…¥æ•°æ®'}
            ],
            'media_resources': [
                {'æ­¥éª¤': '1', 'è¯´æ˜': 'åœ¨"æ¨¡æ¿æ•°æ®"å·¥ä½œè¡¨ä¸­å¡«å†™åª’ä½“èµ„æºä¿¡æ¯'},
                {'æ­¥éª¤': '2', 'è¯´æ˜': 'æ‰€æœ‰å­—æ®µéƒ½ä¸ºå¿…å¡«é¡¹'},
                {'æ­¥éª¤': '3', 'è¯´æ˜': 'åˆŠä¾‹ä»·åº”é«˜äºå®é™…æˆæœ¬'},
                {'æ­¥éª¤': '4', 'è¯´æ˜': 'åª’ä½“ç±»å‹åŒ…æ‹¬: ç¤¾åŒºé—¨ç¦ã€å†™å­—æ¥¼ç”µæ¢¯ç­‰'},
                {'æ­¥éª¤': '5', 'è¯´æ˜': 'ä¿å­˜æ–‡ä»¶åä½¿ç”¨å¯¼å…¥åŠŸèƒ½å¯¼å…¥æ•°æ®'}
            ],
            'sales_channels': [
                {'æ­¥éª¤': '1', 'è¯´æ˜': 'åœ¨"æ¨¡æ¿æ•°æ®"å·¥ä½œè¡¨ä¸­å¡«å†™é”€å”®æ¸ é“ä¿¡æ¯'},
                {'æ­¥éª¤': '2', 'è¯´æ˜': 'æ¸ é“åç§°ã€æ¸ é“ç±»å‹ä¸ºå¿…å¡«é¡¹'},
                {'æ­¥éª¤': '3', 'è¯´æ˜': 'æ¸ é“ç±»å‹: Sçº§(å›¢é•¿)ã€Açº§(æ‰¹å‘å¸‚åœº)'},
                {'æ­¥éª¤': '4', 'è¯´æ˜': 'ä½£é‡‘æ¯”ä¾‹ä¸ºå°æ•°ï¼Œå¦‚5%å¡«å†™5.0'},
                {'æ­¥éª¤': '5', 'è¯´æ˜': 'ä¿å­˜æ–‡ä»¶åä½¿ç”¨å¯¼å…¥åŠŸèƒ½å¯¼å…¥æ•°æ®'}
            ]
        }
        
        return instructions_map.get(template_type, [])
    
    def _generate_column_descriptions(self, template_type: str) -> List[Dict]:
        """ç”Ÿæˆåˆ—è¯´æ˜"""
        descriptions_map = {
            'brands': [
                {'åˆ—å': 'brand_name', 'è¯´æ˜': 'å“ç‰Œåç§°ï¼Œå¿…å¡«ï¼Œå”¯ä¸€', 'ç¤ºä¾‹': 'å¯å£å¯ä¹', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'contact_person', 'è¯´æ˜': 'è”ç³»äººå§“åï¼Œå¯é€‰', 'ç¤ºä¾‹': 'å¼ ç»ç†', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'contact_phone', 'è¯´æ˜': 'è”ç³»ç”µè¯ï¼Œå¯é€‰', 'ç¤ºä¾‹': '13800138000', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'contact_email', 'è¯´æ˜': 'è”ç³»é‚®ç®±ï¼Œå¯é€‰', 'ç¤ºä¾‹': 'zhang@coke.com', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'brand_type', 'è¯´æ˜': 'å“ç‰Œç±»å‹ï¼Œå¯é€‰', 'ç¤ºä¾‹': 'é¥®æ–™', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'reputation_score', 'è¯´æ˜': 'å“ç‰Œå£°èª‰è¯„åˆ†ï¼Œå¯é€‰ï¼Œ1-10', 'ç¤ºä¾‹': '9', 'æ•°æ®ç±»å‹': 'æ•°å­—'}
            ],
            'inventory': [
                {'åˆ—å': 'brand_name', 'è¯´æ˜': 'å“ç‰Œåç§°ï¼Œå¿…å¡«ï¼Œå¿…é¡»å­˜åœ¨', 'ç¤ºä¾‹': 'å¯å£å¯ä¹', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'product_name', 'è¯´æ˜': 'å•†å“åç§°ï¼Œå¿…å¡«', 'ç¤ºä¾‹': 'å¯å£å¯ä¹ç»å…¸è£…', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'category', 'è¯´æ˜': 'å•†å“å“ç±»ï¼Œå¿…å¡«', 'ç¤ºä¾‹': 'é¥®æ–™', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'quantity', 'è¯´æ˜': 'æ•°é‡ï¼Œå¿…å¡«', 'ç¤ºä¾‹': '1000', 'æ•°æ®ç±»å‹': 'æ•°å­—'},
                {'åˆ—å': 'original_value', 'è¯´æ˜': 'åŸå§‹ä»·å€¼ï¼Œå¿…å¡«', 'ç¤ºä¾‹': '45000.0', 'æ•°æ®ç±»å‹': 'æ•°å­—'},
                {'åˆ—å': 'market_value', 'è¯´æ˜': 'å¸‚åœºä»·å€¼ï¼Œå¯é€‰', 'ç¤ºä¾‹': '30000.0', 'æ•°æ®ç±»å‹': 'æ•°å­—'},
                {'åˆ—å': 'expiry_date', 'è¯´æ˜': 'ä¿è´¨æœŸï¼Œå¯é€‰', 'ç¤ºä¾‹': '2025-06-30', 'æ•°æ®ç±»å‹': 'æ—¥æœŸ'},
                {'åˆ—å': 'storage_location', 'è¯´æ˜': 'å­˜å‚¨ä½ç½®ï¼Œå¯é€‰', 'ç¤ºä¾‹': 'ä»“åº“A', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'}
            ],
            'media_resources': [
                {'åˆ—å': 'media_name', 'è¯´æ˜': 'åª’ä½“åç§°ï¼Œå¿…å¡«', 'ç¤ºä¾‹': 'ç¤¾åŒºé—¨ç¦å¹¿å‘Šä½A', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'media_type', 'è¯´æ˜': 'åª’ä½“ç±»å‹ï¼Œå¿…å¡«', 'ç¤ºä¾‹': 'ç¤¾åŒºé—¨ç¦', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'location', 'è¯´æ˜': 'ä½ç½®ï¼Œå¿…å¡«', 'ç¤ºä¾‹': 'æœé˜³åŒºæŸå°åŒº', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'market_price', 'è¯´æ˜': 'åˆŠä¾‹ä»·ï¼Œå¿…å¡«', 'ç¤ºä¾‹': '5000.0', 'æ•°æ®ç±»å‹': 'æ•°å­—'},
                {'åˆ—å': 'actual_cost', 'è¯´æ˜': 'å®é™…æˆæœ¬ï¼Œå¿…å¡«', 'ç¤ºä¾‹': '200.0', 'æ•°æ®ç±»å‹': 'æ•°å­—'}
            ],
            'sales_channels': [
                {'åˆ—å': 'channel_name', 'è¯´æ˜': 'æ¸ é“åç§°ï¼Œå¿…å¡«', 'ç¤ºä¾‹': 'ç‹å›¢é•¿å›¢è´­', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'channel_type', 'è¯´æ˜': 'æ¸ é“ç±»å‹ï¼Œå¿…å¡«', 'ç¤ºä¾‹': 'Sçº§', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'contact_person', 'è¯´æ˜': 'è”ç³»äººï¼Œå¯é€‰', 'ç¤ºä¾‹': 'ç‹å›¢é•¿', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'contact_phone', 'è¯´æ˜': 'è”ç³»ç”µè¯ï¼Œå¯é€‰', 'ç¤ºä¾‹': '13700137000', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'},
                {'åˆ—å': 'commission_rate', 'è¯´æ˜': 'ä½£é‡‘æ¯”ä¾‹ï¼Œå¯é€‰', 'ç¤ºä¾‹': '5.0', 'æ•°æ®ç±»å‹': 'æ•°å­—'},
                {'åˆ—å': 'payment_terms', 'è¯´æ˜': 'ç»“ç®—æ–¹å¼ï¼Œå¯é€‰', 'ç¤ºä¾‹': 'ç°ç»“', 'æ•°æ®ç±»å‹': 'æ–‡æœ¬'}
            ]
        }
        
        return descriptions_map.get(template_type, [])
    
    def import_from_excel(self, filename: str, import_type: str) -> Dict[str, Any]:
        """
        ä»Excelæ–‡ä»¶å¯¼å…¥æ•°æ®
        
        Args:
            filename: Excelæ–‡ä»¶å
            import_type: å¯¼å…¥ç±»å‹ ('brands', 'inventory', 'media_resources', 'sales_channels')
            
        Returns:
            å¯¼å…¥ç»“æœç»Ÿè®¡
        """
        if import_type not in self.templates:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å…¥ç±»å‹: {import_type}")
        
        if not os.path.exists(filename):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        try:
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(filename, sheet_name='æ¨¡æ¿æ•°æ®')
            
            if df.empty:
                return {'success': False, 'message': 'Excelæ–‡ä»¶ä¸ºç©º', 'imported': 0, 'failed': 0}
            
            # éªŒè¯å¿…å¡«å­—æ®µ
            template_info = self.templates[import_type]
            required_fields = template_info['required']
            
            missing_fields = []
            for field in required_fields:
                if field not in df.columns:
                    missing_fields.append(field)
                elif df[field].isnull().all():
                    missing_fields.append(f"{field}(å…¨éƒ¨ä¸ºç©º)")
            
            if missing_fields:
                return {
                    'success': False, 
                    'message': f'ç¼ºå°‘å¿…å¡«å­—æ®µ: {", ".join(missing_fields)}',
                    'imported': 0, 
                    'failed': 0
                }
            
            # æ•°æ®æ¸…æ´—å’ŒéªŒè¯
            df = self._clean_and_validate_data(df, import_type)
            
            # å¯¼å…¥æ•°æ®
            return self._import_data(df, import_type)
            
        except Exception as e:
            logger.error(f"å¯¼å…¥å¤±è´¥: {str(e)}")
            return {'success': False, 'message': f'å¯¼å…¥å¤±è´¥: {str(e)}', 'imported': 0, 'failed': 0}
    
    def _clean_and_validate_data(self, df: pd.DataFrame, import_type: str) -> pd.DataFrame:
        """æ¸…æ´—å’ŒéªŒè¯æ•°æ®"""
        # å»é™¤ç©ºè¡Œ
        df = df.dropna(how='all')
        
        # å»é™¤å‰åç©ºæ ¼
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].astype(str).str.strip()
            # å°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸ºNone
            df[col] = df[col].replace('', None)
        
        # æ•°æ®ç±»å‹è½¬æ¢
        if import_type == 'brands':
            # å£°èª‰è¯„åˆ†è½¬æ¢ä¸ºæ•´æ•°
            if 'reputation_score' in df.columns:
                df['reputation_score'] = pd.to_numeric(df['reputation_score'], errors='coerce')
                df['reputation_score'] = df['reputation_score'].fillna(5)
                df['reputation_score'] = df['reputation_score'].clip(1, 10)
        
        elif import_type == 'inventory':
            # æ•°å€¼å­—æ®µè½¬æ¢
            numeric_fields = ['quantity', 'original_value', 'market_value']
            for field in numeric_fields:
                if field in df.columns:
                    df[field] = pd.to_numeric(df[field], errors='coerce')
            
            # æ—¥æœŸå­—æ®µè½¬æ¢
            if 'expiry_date' in df.columns:
                df['expiry_date'] = pd.to_datetime(df['expiry_date'], errors='coerce')
                df['expiry_date'] = df['expiry_date'].dt.strftime('%Y-%m-%d')
        
        elif import_type == 'media_resources':
            # æ•°å€¼å­—æ®µè½¬æ¢
            numeric_fields = ['market_price', 'actual_cost']
            for field in numeric_fields:
                if field in df.columns:
                    df[field] = pd.to_numeric(df[field], errors='coerce')
        
        elif import_type == 'sales_channels':
            # ä½£é‡‘æ¯”ä¾‹è½¬æ¢
            if 'commission_rate' in df.columns:
                df['commission_rate'] = pd.to_numeric(df['commission_rate'], errors='coerce')
                df['commission_rate'] = df['commission_rate'].fillna(0)
        
        return df
    
    def _import_data(self, df: pd.DataFrame, import_type: str) -> Dict[str, Any]:
        """å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“"""
        from inventory_manager import InventoryManager
        
        manager = InventoryManager()
        imported_count = 0
        failed_count = 0
        errors = []
        
        try:
            conn = sqlite3.connect(manager.db_path)
            cursor = conn.cursor()
            
            for index, row in df.iterrows():
                try:
                    if import_type == 'brands':
                        brand_id = manager.add_brand(
                            brand_name=row['brand_name'],
                            contact_person=row.get('contact_person'),
                            contact_phone=row.get('contact_phone'),
                            contact_email=row.get('contact_email'),
                            brand_type=row.get('brand_type'),
                            reputation_score=row.get('reputation_score', 5)
                        )
                        if brand_id:
                            imported_count += 1
                    
                    elif import_type == 'inventory':
                        # éœ€è¦å…ˆè·å–å“ç‰ŒID
                        brand_name = row['brand_name']
                        cursor.execute('SELECT id FROM brands WHERE brand_name = ?', (brand_name,))
                        brand_result = cursor.fetchone()
                        
                        if brand_result:
                            inventory_id = manager.add_inventory(
                                brand_id=brand_result[0],
                                product_name=row['product_name'],
                                category=row['category'],
                                quantity=int(row['quantity']),
                                original_value=float(row['original_value']),
                                market_value=row.get('market_value'),
                                expiry_date=row.get('expiry_date'),
                                storage_location=row.get('storage_location')
                            )
                            if inventory_id:
                                imported_count += 1
                        else:
                            failed_count += 1
                            errors.append(f"ç¬¬{index + 1}è¡Œ: å“ç‰Œ '{brand_name}' ä¸å­˜åœ¨")
                    
                    elif import_type == 'media_resources':
                        resource_id = manager.add_media_resource(
                            media_name=row['media_name'],
                            media_type=row['media_type'],
                            location=row['location'],
                            market_price=float(row['market_price']),
                            actual_cost=float(row['actual_cost'])
                        )
                        if resource_id:
                            imported_count += 1
                    
                    elif import_type == 'sales_channels':
                        channel_id = manager.add_sales_channel(
                            channel_name=row['channel_name'],
                            channel_type=row['channel_type'],
                            contact_person=row.get('contact_person'),
                            contact_phone=row.get('contact_phone'),
                            commission_rate=row.get('commission_rate', 0),
                            payment_terms=row.get('payment_terms')
                        )
                        if channel_id:
                            imported_count += 1
                
                except Exception as e:
                    failed_count += 1
                    errors.append(f"ç¬¬{index + 1}è¡Œ: {str(e)}")
            
            conn.close()
            
            result = {
                'success': True,
                'imported': imported_count,
                'failed': failed_count,
                'total': len(df)
            }
            
            if errors:
                result['errors'] = errors[:10]  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
            
            logger.info(f"æ•°æ®å¯¼å…¥å®Œæˆ: æˆåŠŸ {imported_count}, å¤±è´¥ {failed_count}")
            return result
            
        except Exception as e:
            logger.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'message': f'æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}',
                'imported': imported_count,
                'failed': failed_count
            }
    
    def export_to_csv(self, table_name: str, filename: str = None) -> str:
        """
        å¯¼å‡ºæ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            table_name: è¡¨å
            filename: è¾“å‡ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶å
        """
        if not filename:
            filename = f"{table_name}_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            # è·å–è¡¨æ•°æ®
            if table_name == 'inventory':
                query = '''
                    SELECT i.*, b.brand_name 
                    FROM inventory i
                    LEFT JOIN brands b ON i.brand_id = b.id
                '''
            elif table_name == 'transactions':
                query = '''
                    SELECT 
                        t.*,
                        i.product_name,
                        b.brand_name,
                        ar.resource_name,
                        sc.channel_name
                    FROM transactions t
                    LEFT JOIN inventory i ON t.inventory_id = i.id
                    LEFT JOIN brands b ON t.brand_id = b.id
                    LEFT JOIN ad_resources ar ON t.ad_resource_id = ar.id
                    LEFT JOIN sales_channels sc ON t.channel_id = sc.id
                '''
            else:
                query = f'SELECT * FROM {table_name}'
            
            df = pd.read_sql_query(query, conn)
            conn.close()
            
            if df.empty:
                logger.warning(f"è¡¨ {table_name} æ²¡æœ‰æ•°æ®")
                return None
            
            # å¯¼å‡ºåˆ°CSV
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            logger.info(f"æ•°æ®å·²å¯¼å‡ºåˆ°CSV: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"CSVå¯¼å‡ºå¤±è´¥: {str(e)}")
            return None
    
    def validate_data_quality(self, filename: str, data_type: str) -> Dict[str, Any]:
        """
        éªŒè¯æ•°æ®è´¨é‡
        
        Args:
            filename: æ•°æ®æ–‡ä»¶è·¯å¾„
            data_type: æ•°æ®ç±»å‹
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            # è¯»å–æ•°æ®
            if filename.endswith('.xlsx'):
                df = pd.read_excel(filename, sheet_name='æ¨¡æ¿æ•°æ®')
            elif filename.endswith('.csv'):
                df = pd.read_csv(filename)
            else:
                return {'valid': False, 'message': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}
            
            if df.empty:
                return {'valid': False, 'message': 'æ–‡ä»¶ä¸ºç©º'}
            
            # åŸºæœ¬éªŒè¯
            validation_result = {
                'valid': True,
                'total_rows': len(df),
                'missing_required': 0,
                'data_type_errors': 0,
                'duplicate_entries': 0,
                'warnings': []
            }
            
            # éªŒè¯å¿…å¡«å­—æ®µ
            template_info = self.templates[data_type]
            required_fields = template_info['required']
            
            for field in required_fields:
                if field not in df.columns:
                    validation_result['warnings'].append(f'ç¼ºå°‘å­—æ®µ: {field}')
                else:
                    missing_count = df[field].isnull().sum()
                    if missing_count > 0:
                        validation_result['missing_required'] += missing_count
                        validation_result['warnings'].append(f'å­—æ®µ {field} æœ‰ {missing_count} ä¸ªç¼ºå¤±å€¼')
            
            # éªŒè¯æ•°æ®ç±»å‹
            if data_type == 'brands' and 'reputation_score' in df.columns:
                invalid_scores = df[~df['reputation_score'].between(1, 10)]
                if len(invalid_scores) > 0:
                    validation_result['data_type_errors'] += len(invalid_scores)
                    validation_result['warnings'].append(f'å£°èª‰è¯„åˆ†è¶…å‡ºèŒƒå›´ (1-10): {len(invalid_scores)} ä¸ª')
            
            # æ£€æŸ¥é‡å¤é¡¹
            if 'brand_name' in df.columns:
                duplicates = df[df.duplicated(subset=['brand_name'], keep=False)]
                if len(duplicates) > 0:
                    validation_result['duplicate_entries'] = len(duplicates)
                    validation_result['warnings'].append(f'å‘ç°é‡å¤çš„å“ç‰Œåç§°: {len(duplicates)} ä¸ª')
            
            # æ€»ä½“è¯„ä¼°
            total_warnings = (validation_result['missing_required'] + 
                            validation_result['data_type_errors'] + 
                            validation_result['duplicate_entries'])
            
            if total_warnings == 0:
                validation_result['quality'] = 'ä¼˜ç§€'
            elif total_warnings < len(df) * 0.1:  # é”™è¯¯ç‡å°äº10%
                validation_result['quality'] = 'è‰¯å¥½'
            elif total_warnings < len(df) * 0.2:  # é”™è¯¯ç‡å°äº20%
                validation_result['quality'] = 'ä¸€èˆ¬'
            else:
                validation_result['quality'] = 'è¾ƒå·®'
                validation_result['valid'] = False
            
            return validation_result
            
        except Exception as e:
            return {'valid': False, 'message': f'éªŒè¯å¤±è´¥: {str(e)}'}

def main():
    """ä¸»å‡½æ•°"""
    importer = DataImporter()
    
    # ç¤ºä¾‹ï¼šç”Ÿæˆæ¨¡æ¿
    print("=== æ•°æ®å¯¼å…¥å¯¼å‡ºå·¥å…· ===")
    
    while True:
        print("\nğŸ“‹ ä¸»èœå•:")
        print("  1. ç”Ÿæˆæ•°æ®æ¨¡æ¿")
        print("  2. å¯¼å…¥Excelæ•°æ®")
        print("  3. å¯¼å‡ºCSVæ•°æ®")
        print("  4. éªŒè¯æ•°æ®è´¨é‡")
        print("  0. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-4): ").strip()
        
        if choice == '0':
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        elif choice == '1':
            print("\nå¯ç”Ÿæˆçš„æ¨¡æ¿ç±»å‹:")
            template_types = ['brands', 'inventory', 'media_resources', 'sales_channels']
            for i, template_type in enumerate(template_types, 1):
                print(f"  {i}: {template_type}")
            
            try:
                template_choice = int(input("é€‰æ‹©æ¨¡æ¿ç±»å‹ (1-4): "))
                if 1 <= template_choice <= 4:
                    template_type = template_types[template_choice - 1]
                    filename = importer.generate_template(template_type)
                    print(f"âœ… æ¨¡æ¿å·²ç”Ÿæˆ: {filename}")
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        elif choice == '2':
            filename = input("è¾“å…¥Excelæ–‡ä»¶è·¯å¾„: ").strip()
            if os.path.exists(filename):
                print("\nå¯¼å…¥ç±»å‹:")
                for i, import_type in enumerate(['brands', 'inventory', 'media_resources', 'sales_channels'], 1):
                    print(f"  {i}: {import_type}")
                
                try:
                    import_choice = int(input("é€‰æ‹©å¯¼å…¥ç±»å‹ (1-4): "))
                    if 1 <= import_choice <= 4:
                        import_type = ['brands', 'inventory', 'media_resources', 'sales_channels'][import_choice - 1]
                        result = importer.import_from_excel(filename, import_type)
                        if result['success']:
                            print(f"âœ… å¯¼å…¥å®Œæˆ: æˆåŠŸ {result['imported']}, å¤±è´¥ {result['failed']}")
                            if 'errors' in result:
                                print("é”™è¯¯ä¿¡æ¯:")
                                for error in result['errors']:
                                    print(f"  - {error}")
                        else:
                            print(f"âŒ å¯¼å…¥å¤±è´¥: {result['message']}")
                    else:
                        print("âŒ æ— æ•ˆé€‰æ‹©")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        
        elif choice == '3':
            print("\nå¯å¯¼å‡ºçš„è¡¨:")
            tables = ['brands', 'inventory', 'media_resources', 'sales_channels', 'transactions']
            for i, table in enumerate(tables, 1):
                print(f"  {i}: {table}")
            
            try:
                export_choice = int(input("é€‰æ‹©å¯¼å‡ºè¡¨ (1-5): "))
                if 1 <= export_choice <= 5:
                    table_name = tables[export_choice - 1]
                    filename = input("è¾“å‡ºæ–‡ä»¶å (å¯é€‰ï¼Œç•™ç©ºè‡ªåŠ¨ç”Ÿæˆ): ").strip()
                    result = importer.export_to_csv(table_name, filename if filename else None)
                    if result:
                        print(f"âœ… æ•°æ®å·²å¯¼å‡º: {result}")
                    else:
                        print("âŒ å¯¼å‡ºå¤±è´¥")
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        elif choice == '4':
            filename = input("è¾“å…¥è¦éªŒè¯çš„æ–‡ä»¶è·¯å¾„: ").strip()
            if os.path.exists(filename):
                print("\næ•°æ®ç±»å‹:")
                for i, data_type in enumerate(['brands', 'inventory', 'media_resources', 'sales_channels'], 1):
                    print(f"  {i}: {data_type}")
                
                try:
                    validate_choice = int(input("é€‰æ‹©æ•°æ®ç±»å‹ (1-4): "))
                    if 1 <= validate_choice <= 4:
                        data_type = ['brands', 'inventory', 'media_resources', 'sales_channels'][validate_choice - 1]
                        result = importer.validate_data_quality(filename, data_type)
                        if result['valid']:
                            print(f"âœ… æ•°æ®è´¨é‡: {result['quality']}")
                            print(f"æ€»è¡Œæ•°: {result['total_rows']}")
                            print(f"ç¼ºå¤±å¿…å¡«é¡¹: {result['missing_required']}")
                            print(f"æ•°æ®ç±»å‹é”™è¯¯: {result['data_type_errors']}")
                            print(f"é‡å¤é¡¹: {result['duplicate_entries']}")
                            if result['warnings']:
                                print("è­¦å‘Šä¿¡æ¯:")
                                for warning in result['warnings']:
                                    print(f"  - {warning}")
                        else:
                            print(f"âŒ éªŒè¯å¤±è´¥: {result['message']}")
                    else:
                        print("âŒ æ— æ•ˆé€‰æ‹©")
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()